{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alpine-productivity",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cls_batch_num=30, cls_image_shape='3, 48, 192', cls_model_dir='C:\\\\Users\\\\GNG/.paddleocr/2.0/cls', cls_thresh=0.9, det=True, det_algorithm='DB', det_db_box_thresh=0.5, det_db_thresh=0.3, det_db_unclip_ratio=2.0, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_limit_side_len=960, det_limit_type='max', det_model_dir='C:\\\\Users\\\\GNG/.paddleocr/2.0/det', drop_score=0.5, enable_mkldnn=False, gpu_mem=8000, image_dir='', ir_optim=True, label_list=['0', '180'], lang='en', max_text_length=25, rec=True, rec_algorithm='CRNN', rec_batch_num=30, rec_char_dict_path='./ppocr/utils/dict/en_dict.txt', rec_char_type='ch', rec_image_shape='3, 32, 320', rec_model_dir='C:\\\\Users\\\\GNG/.paddleocr/2.0/rec/en', use_angle_cls=True, use_gpu=True, use_pdserving=False, use_space_char=True, use_tensorrt=False, use_zero_copy_run=False)\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR,draw_ocr\n",
    "import cv2\n",
    "import random\n",
    "import pytesseract\n",
    "from PIL import Image, ImageDraw \n",
    "from PIL import ImagePath  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import json\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-uzbekistan",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-lithuania",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Get the min x and y\n",
    "\n",
    "We only need ocr of first part of the page. So we are going to take the min x and y on the image detected that will be most probably the name of in the card than we will try to crop it slightly before the first page ends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "certain-posting",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_boxes(p_ocr_result):\n",
    "    '''\n",
    "    Description:\n",
    "        This fucntion use paddle ocr for text detection after detecting text it will take only\n",
    "        the fields that we need.\n",
    "        \n",
    "    Abberivation: \n",
    "        p_ocr_result : Paddle ocr result\n",
    "        x_point      : x points of the polygon\n",
    "        \n",
    "    \n",
    "    Input:\n",
    "        p_ocr_result(dict) : Takes paddle ocr results as input\n",
    "        \n",
    "    Output:\n",
    "        first_eight_bbox (list) : List of first eight boxes i.e important\n",
    "        \n",
    "    '''\n",
    "    # Get x_points from the results\n",
    "    x_points = [polygon[0][0] for polygon in p_ocr_result]\n",
    "    # Sort according to the minimum x point values and than sort again for minimum y value\n",
    "    first_eight_bbox= sorted(sorted(p_ocr_result, key = lambda x: x[0][0][0])[:8], key = lambda x: x[1])\n",
    "    # Getting the above three boxes\n",
    "    top_three_bbox= sorted(p_ocr_result, key = lambda x: x[0][0][1])[:3]\n",
    "    # extending both of the above lists\n",
    "    first_eight_bbox.extend(top_three_bbox)\n",
    "    return first_eight_bbox\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-maldives",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Crop Fields\n",
    " to pass again to OCR for Better accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "peripheral-disabled",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_ocr(PIL_Image):\n",
    "    '''\n",
    "    Description:\n",
    "        We are using tesseract to predict text from the image.\n",
    "        \n",
    "    Input:\n",
    "        PIL_IMAGE (PIL): Image\n",
    "        \n",
    "    Output:\n",
    "        text (str) : Text on the image\n",
    "    '''\n",
    "    # Setting mode of the tesseract\n",
    "    custom_oem_psm_config = r'--oem 3 --psm 6'\n",
    "    # Passing image to the tesseract to get text\n",
    "    text = pytesseract.image_to_string(PIL_Image, lang='eng+thai', config=custom_oem_psm_config)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "MODEL_PATH = \"models/model.hdf5\"\n",
    "MODEL      = load_model(MODEL_PATH)\n",
    "def check_orientation(PIL_IMAGE):\n",
    "    '''\n",
    "    Description:\n",
    "        We are using model to get the orientation of the image so that we can rotate image at angle 0 \n",
    "        and get the required results\n",
    "    \n",
    "    '''\n",
    "    # Loading Model\n",
    "\n",
    "\n",
    "    # Inference variables\n",
    "    LABELS     = [0,90,180, 270]\n",
    "    # preprocessing\n",
    "    np_array = np.expand_dims(np.asarray(PIL_IMAGE.resize((224,224))), axis = 0)\n",
    "    # Prediction\n",
    "    prediction = np.argmax(MODEL.predict(np_array))\n",
    "    \n",
    "    return 360 - LABELS[prediction]\n",
    "\n",
    "def get_text(img_path, first_eight_bbox):\n",
    "    '''\n",
    "    Description:\n",
    "        This function get the text from the image by using other fucntions.\n",
    "        \n",
    "    Input:\n",
    "        img_path           (str)  :  path of the image\n",
    "        first_eight_bbox   (dict) : First eight necessary boxes from which we need text\n",
    "     \n",
    "    output:\n",
    "        first_eight_bbox   (dict) : returns dict with the text\n",
    "    '''\n",
    "    # Reading Image by PIL\n",
    "    full_img = Image.open(img_path)\n",
    "    # Process only first eight boxes\n",
    "    for i in first_eight_bbox:\n",
    "        # Cropping\n",
    "        im1 = full_img.crop((i[0][0][0], i[0][0][1], i[0][2][0],i[0][2][1]))\n",
    "        # Converting to np array for further open cv processing\n",
    "        img = np.asarray(im1)\n",
    "        # Applyinmg bilitreal filter                \n",
    "        img = cv2.bilateralFilter(img, 9,20, 20)\n",
    "        # Extracting Text from the image\n",
    "        i[1] = get_ocr(img)\n",
    "\n",
    "    return first_eight_bbox\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-exemption",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Plot OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "partial-differential",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002329F6322F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002329F6322F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002329F6322F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[2021/03/12 00:11:34] root INFO: dt_boxes num : 58, elapse : 0.45777320861816406\n",
      "[2021/03/12 00:11:34] root INFO: cls num  : 58, elapse : 0.6013710498809814\n",
      "[2021/03/12 00:11:36] root INFO: rec_res num  : 58, elapse : 1.8131756782531738\n",
      "[2021/03/12 00:11:39] root INFO: dt_boxes num : 57, elapse : 0.3949434757232666\n",
      "[2021/03/12 00:11:40] root INFO: cls num  : 57, elapse : 0.6093387603759766\n",
      "[2021/03/12 00:11:42] root INFO: rec_res num  : 57, elapse : 1.7372305393218994\n",
      "[2021/03/12 00:11:45] root INFO: dt_boxes num : 45, elapse : 0.4776420593261719\n",
      "[2021/03/12 00:11:45] root INFO: cls num  : 45, elapse : 0.47373127937316895\n",
      "[2021/03/12 00:11:46] root INFO: rec_res num  : 45, elapse : 0.8302600383758545\n",
      "[2021/03/12 00:11:49] root INFO: dt_boxes num : 57, elapse : 0.45478320121765137\n",
      "[2021/03/12 00:11:50] root INFO: cls num  : 57, elapse : 0.5945367813110352\n",
      "[2021/03/12 00:11:52] root INFO: rec_res num  : 57, elapse : 1.644266128540039\n",
      "[2021/03/12 00:11:55] root INFO: dt_boxes num : 55, elapse : 0.39696574211120605\n",
      "[2021/03/12 00:11:55] root INFO: cls num  : 55, elapse : 0.5745699405670166\n",
      "[2021/03/12 00:11:57] root INFO: rec_res num  : 55, elapse : 1.3543858528137207\n",
      "[2021/03/12 00:12:09] root INFO: dt_boxes num : 111, elapse : 8.670131206512451\n",
      "[2021/03/12 00:12:10] root INFO: cls num  : 111, elapse : 1.1429481506347656\n",
      "[2021/03/12 00:12:12] root INFO: rec_res num  : 111, elapse : 2.073462724685669\n",
      "[2021/03/12 00:12:25] root INFO: dt_boxes num : 101, elapse : 8.681225538253784\n",
      "[2021/03/12 00:12:26] root INFO: cls num  : 101, elapse : 1.0551767349243164\n",
      "[2021/03/12 00:12:29] root INFO: rec_res num  : 101, elapse : 2.8691375255584717\n",
      "[2021/03/12 00:12:42] root INFO: dt_boxes num : 104, elapse : 8.303337097167969\n",
      "[2021/03/12 00:12:43] root INFO: cls num  : 104, elapse : 1.0827338695526123\n",
      "[2021/03/12 00:12:46] root INFO: rec_res num  : 104, elapse : 2.7025492191314697\n",
      "[2021/03/12 00:12:59] root INFO: dt_boxes num : 94, elapse : 8.478524208068848\n",
      "[2021/03/12 00:13:00] root INFO: cls num  : 94, elapse : 1.0003249645233154\n",
      "[2021/03/12 00:13:03] root INFO: rec_res num  : 94, elapse : 2.6211674213409424\n",
      "[2021/03/12 00:13:16] root INFO: dt_boxes num : 103, elapse : 8.259023904800415\n",
      "[2021/03/12 00:13:17] root INFO: cls num  : 103, elapse : 1.1316378116607666\n",
      "[2021/03/12 00:13:20] root INFO: rec_res num  : 103, elapse : 3.172964334487915\n",
      "[2021/03/12 00:13:33] root INFO: dt_boxes num : 103, elapse : 8.187161207199097\n",
      "[2021/03/12 00:13:34] root INFO: cls num  : 103, elapse : 1.0561771392822266\n",
      "[2021/03/12 00:13:37] root INFO: rec_res num  : 103, elapse : 2.964202404022217\n",
      "[2021/03/12 00:13:41] root INFO: dt_boxes num : 52, elapse : 0.46276092529296875\n",
      "[2021/03/12 00:13:42] root INFO: cls num  : 52, elapse : 0.536675214767456\n",
      "[2021/03/12 00:13:43] root INFO: rec_res num  : 52, elapse : 1.102635383605957\n",
      "[2021/03/12 00:13:55] root INFO: dt_boxes num : 81, elapse : 8.352596521377563\n",
      "[2021/03/12 00:13:56] root INFO: cls num  : 81, elapse : 0.8287818431854248\n",
      "[2021/03/12 00:13:57] root INFO: rec_res num  : 81, elapse : 1.8620493412017822\n",
      "[2021/03/12 00:14:10] root INFO: dt_boxes num : 85, elapse : 8.132044076919556\n",
      "[2021/03/12 00:14:11] root INFO: cls num  : 85, elapse : 0.8796799182891846\n",
      "[2021/03/12 00:14:14] root INFO: rec_res num  : 85, elapse : 2.8134078979492188\n",
      "[2021/03/12 00:14:26] root INFO: dt_boxes num : 100, elapse : 8.12779974937439\n",
      "[2021/03/12 00:14:28] root INFO: cls num  : 100, elapse : 1.025346279144287\n",
      "[2021/03/12 00:14:30] root INFO: rec_res num  : 100, elapse : 2.4666459560394287\n",
      "[2021/03/12 00:14:43] root INFO: dt_boxes num : 86, elapse : 8.168220281600952\n",
      "[2021/03/12 00:14:43] root INFO: cls num  : 86, elapse : 0.8817689418792725\n",
      "[2021/03/12 00:14:46] root INFO: rec_res num  : 86, elapse : 2.4555935859680176\n",
      "[2021/03/12 00:14:59] root INFO: dt_boxes num : 95, elapse : 8.283263444900513\n",
      "[2021/03/12 00:15:00] root INFO: cls num  : 95, elapse : 0.9754188060760498\n",
      "[2021/03/12 00:15:02] root INFO: rec_res num  : 95, elapse : 2.5283353328704834\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected Ptr<cv::UMat> for argument '%s'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b8dc3a1f244a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[0msave_path\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[1;34m\"images/output/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mget_text_from_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-b8dc3a1f244a>\u001b[0m in \u001b[0;36mget_text_from_images\u001b[1;34m(image_path, save_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mresult\u001b[0m               \u001b[1;33m=\u001b[0m \u001b[0mocr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mocr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mfirst_eight_bbox\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0mget_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mfirst_eight_bbox\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_eight_bbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;31m# Plotting image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-768c92068c6b>\u001b[0m in \u001b[0;36mget_text\u001b[1;34m(img_path, first_eight_bbox)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# Applyinmg bilitreal filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbilateralFilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;31m# Extracting Text from the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ocr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument '%s'"
     ]
    }
   ],
   "source": [
    "def get_text_from_images(image_path ,save_path = ''):\n",
    "    '''\n",
    "    Description:\n",
    "        Just pass list of images to this fuction it will get text from the images and save on the path you\n",
    "        pass to the function.\n",
    "        \n",
    "    Input:\n",
    "        images_list  (list) : List of the images\n",
    "        save_path    (str)  : Path where you want to save the results\n",
    "    '''\n",
    "    images_list = glob.glob(image_path)\n",
    "    assert len(images_list) != 0 , \"No Images found\"\n",
    "    for img_path in  images_list:   \n",
    "        try:\n",
    "            # Reading image\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img = img.rotate(check_orientation(img), expand = True)\n",
    "            img.save(img_path)\n",
    "\n",
    "            # Getting ocr\n",
    "            result               = ocr.ocr(img_path, cls=True)\n",
    "            first_eight_bbox     = get_boxes(result)\n",
    "            first_eight_bbox     = get_text(img_path, first_eight_bbox)\n",
    "\n",
    "            # Plotting image\n",
    "            img1 = ImageDraw.Draw(img)   \n",
    "            for polygon in first_eight_bbox:\n",
    "                text    = \"\".join([i for i in polygon[1] if i.isalpha() or i.isdigit() or i == ' '])\n",
    "                xy      = [tuple(i) for i in polygon[0]]\n",
    "                img1.polygon(xy, outline =\"blue\") \n",
    "                img1.text(xy[0], text)\n",
    "            \n",
    "            # saving preprocessed Image\n",
    "            if save_path != '':\n",
    "                # saving Image\n",
    "                os.system(\"mkdir '{}'\".format(save_path))\n",
    "                image_name = img_path.rsplit(\"\\\\\",1)[1]\n",
    "                temp_save  = \"{}Processed{}\".format(save_path, image_name) \n",
    "                img.save(temp_save)\n",
    "                \n",
    "                # Saving results\n",
    "                with open(save_path+\".txt\", 'w') as outfile:\n",
    "                    json.dump(first_eight_bbox, outfile)\n",
    "                \n",
    "            img.show()\n",
    "        except StopIteration as e:\n",
    "            print(\"Exception occurred \", e)\n",
    "\n",
    "image_path  = \"images\\\\*.*g\"\n",
    "save_path   = \"images/output/\"\n",
    "\n",
    "get_text_from_images(image_path ,save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-workplace",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test Rotated Images\n",
    "\n",
    "Rotate image if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-inflation",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "img_path = \"images\\\\11.jpg\"\n",
    "img = Image.open(img_path)\n",
    "img = img.rotate(180, expand=1)\n",
    "img.save(img_path)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-chambers",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-principal",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-correlation",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-sperm",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "ocr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
